## Maldet Tests

### Concept:

1. Create a framework for tests that can be run to confirm or deny the effectiveness of changes that were made.
2. Create tests for the most recent pull requests that conform to the rules laid out herein, both to confirm the effectiveness of those pull requests, and to serve as examples for the creation of future tests.
3. Over time grow a body of historical tests that will be able to be run against future versions of Linux Malware Detect in order increase awareness of situations where new environments or recent updates have broken historical functionality.

### Test Rules:

1. The script "/usr/local/maldetect/tests/test.sh" will iterate through all of the test scripts that follow the naming conventions (see below). Optionally, test.sh can be given an argument of the name of one or more specific test scripts to run (whether or not the meet the naming conventions).
2. The "test.sh" script will export the following variables to be used by the test scripts that it runs:
   - $d\_MALDET - The directory "/usr/local/maldetect"
   - $d\_MALDET\_TESTS - The directory "/usr/local/maldetect/tests"
   - $d\_MALDET\_TESTS\_WORKING - The directory "/usr/local/maldetect/tests/working"
3. The test scripts should only create, modify, or destroy files within $d\_MALDET\_TESTS\_WORKING.
   - Typical functions of Maldet may, of course, modify other files outside of this.
4. If the tests within a test script are considered to have failed, they need to exit with "exit 1" or some other non-zero exit code. test.sh will stop when it encounters a test that exited in this manner.
5. The tests scripts should not be executable; test.sh will toggle their executability as needed.
6. It is preferred when ever possible that the tests actually run the executable they are testing (usually "maldet"). If this is not possible, copying files from the project and modifying them in-line is the preferred alternative.
   - Under such circumstances, the test script must give warning output indicating that such is the case.
     - See tests_000299.sh for an example of this.
7. There is no expectation that every slightest change be tested.
   - Example: The changes from pull request 300 are simple, self-evident, and should work across all versions of bash; writing a test for them seems silly.
   - Example: Functionality unchanged from version 1.6.2 or before has been used heavily enough that if there are issues, it is likely that they either would have come to light by now, or are so edge-case that tests might fail to capture them anyway.
   - This all being said, testing changes really is a best practice

### Conventions:

1. File Names: Test scripts should be named like the following: "tests_[NUMBER].[EXTENSION]"
   - In the instances where the change is associated with a pull request or an issue, the number will be the number of that pull request or issue represented in six digits with leading zeros.
     - Because the pull request number cannot be known for certain beforehand, it is acceptable when submitting pull requests that include a test script to give it any name beginning with "tests_". This will be changed at a later date to match the format specified above.
   - In the instances where the change is NOT associated with a pull request or an issue, the number will be the date on which the commit was made in eight digit "YYYYMMDD" format, optionally with an underscore and more numbers following (if multiple test files need to be added on a single date).
   - The purpose of this naming system is to make it easy to go back through the git history to find more details on what the test is supposed to be testing against.
2. Colored Output: When possible, colored output should be used under the following circumstances:
   - Blue (\e[34m) at the beginning of the test for a brief description of what's being tested.
   - Yellow (\e[33m) to indicate soft-fails or important information that the user needs to be aware of.
   - Green (\e[32m) to indicate success.
   - Red (\e[31m) to indicate hard failures or critical warnings.
